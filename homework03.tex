\documentclass{article}
\usepackage{graphicx} 
\usepackage{theJackPack}

\title{Homework 3 - Jack Brolin, Abhiram Nallamalli}
\author{Jack Brolin}
\date{July 2023}

\begin{document}

\maketitle

\begin{jacklist}
    \begin{framed} 
    \item [\textbf{P. 2}] Let $P=\left\{x \in \mathbb{R}^{3} \mid x_{1}+x_{2}+x_{3}=1, x \geq 0\right\}$ and consider the vector 
        $x=(0,0,1)$. Find the set of feasible directions at $x$.
    \end{framed}
    \begin{proof}
        Let $d = (a,b,c); a,b,c \in \mathbb{R}$. Then 
        \begin{align*}
            &(0 + \theta a) + (0 + \theta b ) + (1 + \theta c) = 1 \\
            \Rightarrow \quad &(a + b + c)\theta  = 0 \\
            \Rightarrow \quad &a + b + c = 0 
        \end{align*}
        and thus $c = -a - b$. Since $x = (0,0,1)$, we must require $a,b > 0$ so the shift meets the condition at $x \geq 0$. 
        Furthermore, we must also require $1 + \theta c \leq 0 \Rightarrow 1 \geq \theta(a+b) \Rightarrow \frac{1}{a+b} \geq \theta$.
        This is always satisfied by $a > 0$ or $b > 0$. We get our final set of feasible directions: 
        \[ 
            d = \{(a,b,-a-b) : a,b \geq 0 \}
        \] 
    \end{proof}

\newpage
    \begin{framed} 
    \item [\textbf{P. 3}] Consider the problem of minimizing $c^{\prime} x$ over a polyhedron $P$. Prove the following:
        \begin{itemize}
            \item [a.] A feasible solution $x$ is optimal if and only if $c^{\prime} d \geq 0$ for every feasible direction $d$ at $x$. 
            \item [b.] A feasible solution $x$ is the unique optimal solution if and only if $c^{\prime} d>0$ 
                for every nonzero feasible direction $d$ at $x$. 
        \end{itemize}
    \end{framed}
    \begin{itemize}
        \item [a.] 
            \begin{proof}
                Assume $x$ is an optimal solution and let $d$ be any arbitrary feasible direction vector at $x$. Then $x + \theta d 
                \in P$ for some $\theta > 0$. For this new vector, 
                \begin{align*}
                    \text{optimality of } x \Leftrightarrow c^\prime x^\star &\leq c^\prime(x^\star + \theta d) \\
                    \Leftrightarrow c^\prime x^\star &\leq c^\prime x^\star + \theta c^\prime d \\
                    \Leftrightarrow 0 &\leq \theta c^\prime d \\
                    \Leftrightarrow 0 &\leq c^\prime d
                \end{align*}
                Because the algebra works in both directions, and we know $\theta > 0$, the sufficient condition are shown 
                bi-conditionally. 
            \end{proof}
        \item [b.]
    \end{itemize}

\newpage
    \begin{framed} 
    \item [\textbf{P. 4}] Let $x$ be an element of the standard form polyhedron 
        $P=\left\{x \in \mathbb{R}^{n} \mid A x=b, x \geq 0\right\}$. Prove that a vector $d \in \mathbb{R}^{n}$ is a feasible 
        direction at $x$ if and only if $A d=0$ and $d_{i} \geq 0$ for every $i$ such that $x_{i}=0$.
    \end{framed}

\newpage
    \begin{framed} 
    \item [\textbf{P. 7}] Consider a feasible solution $x$ to the standard form problem 
        \begin{align*}
            \text{minimize } & c^{\prime} x \\
            \text { subject to } & A x=b \\
            & x \geq 0,
        \end{align*}
        and let $Z=\left\{i: x_{i}=0\right\}$. Show that $x$ is an optimal solution if and only if the linear programming problem
        \begin{align*}
            \text{minimize } & c^{\prime} d \\
            \text { subject to } & A d=0 \quad \\
            & d_{i} \geq 0, \quad i \in Z,
        \end{align*}
        has an optimal cost of zero.
    \end{framed}
    \begin{proof}
        Start
    \end{proof}

\newpage
    \begin{framed} 
    \item [\textbf{P. 9}] Consider the problem 
        \[\begin{array}{rc}
            \operatorname{minimize} & -2 x_{1}-x_{2} \\
            \text { subject to } & x_{1}-x_{2} \leq 2 \\
            & x_{1}+x_{2} \leq 6 \\
            & x_{1}, x_{2} \geq 0
        \end{array}\]
    \end{framed}
    We first find the equivalent standard form representation: 
    \begin{align*}
        \text{min } -&2x_1 - x_2 \\
        \text{s.t. } &x_1 - x_2 + x_3 = 2 \\
                     &x_1 + x_2 + x_4 = 6 \\
                     & x \geq 0
    \end{align*}
    and we can immediately see that $x = (0,0,2,6)$ is a basic feasible solution and so we let $B(1) = 3$ and $B(2) = 4$ giving a 
    basis matrix of $I$. Filling in the first tableau is trivial, as the necessary conditions arise very naturally: 
    \begin{center}
        \begin{tabular}{|c|cccc|}
           \hline 
           0 & -2 & -1 & 0 & 0 \\
           \hline 
           2 & 1 & -1 & 1 & 0 \\
           6 & 1 & 1 & 0 & 1 \\
           \hline
        \end{tabular}
    \end{center}
    Both relevant values in the $0^{\text{th}}$ are negative so we make an arbitrary choice of the second column $x_2$ and get
    $u = (-1,1)$. We only need to consider the ratio between $ \displaystyle \frac{x_{B(2)}}{u_2}$ as $u_1 < 0$ to get $\ell = 2$. 
    This gives our pivot element and choice of vector to enter the basis. Computing our version of Echelon Reduction we get the next 
    tableau: 
    \begin{center}
        \begin{tabular}{|c|cccc|}
            \hline
            6&-1&0&0&1 \\
            \hline 
            8&2&0&1&1\\
            6&1&1&0&1\\
            \hline
        \end{tabular}
    \end{center} 
    We only have one choice for our pivot column and we get $u = (2,1)$ with ratios 
    \begin{align*}
        &\frac{x_{B(1)}}{u_1} = \frac{8}{2} = 4 \\
        &\frac{x_{(2)}}{u_2} = \frac{6}{1} = 6 
    \end{align*}
    So we let $\ell = 1$ which corresponds to $x_3$. Now, with 2 as our pivot variable, we can run the next round of reductions and 
    get the last tableau: 
    \begin{center}
        \begin{tabular}{|c|cccc|}
            \hline
            10&0&0&$\rfrac{1}{2}$&$\rfrac{3}{2}$ \\
            \hline
            4&1&0&$\rfrac{1}{2}$&$\rfrac{1}{2}$ \\
            2&0&1&$\rfrac{1}{2}$&$\rfrac{3}{2}$ \\
            \hline
        \end{tabular}
    \end{center}
    With no more negative values in the reduced cost vector, we are sure that we are done and have achieved the optimal solution. 
    At every step we can do a confidence check and compute the values of the needed vector and make sure that each is a basic feasible 
    solution. We know at all times what row corresponds to what component by considering the components we choice to enter the basis,
    but in practice we just look at the unit vector in specific columns to get the corresponding components. This allows us to see our 
    final answer of $x = (4,2)$ which is chosen to minimize the above cost vector. 
\end{jacklist}

\end{document}
